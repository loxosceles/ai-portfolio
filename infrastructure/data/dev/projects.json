[
  {
    "id": "proj-1",
    "title": "AI-Powered Portfolio",
    "slug": "ai-portfolio",
    "icon": "Bot",
    "description": "A modern, serverless web application that showcases a developer's professional profile with AI-powered personalization features using Next.js and AWS services.",
    "status": "Active",
    "highlights": [
      "AI-powered content personalization with Amazon Bedrock",
      "Invisible authentication using virtual Cognito users",
      "Multi-region serverless architecture",
      "Comprehensive CI/CD with environment management"
    ],
    "techStack": [
      "Next.js",
      "TypeScript",
      "AWS AppSync",
      "AWS Lambda",
      "DynamoDB",
      "Amazon Bedrock",
      "CloudFront",
      "S3",
      "Cognito",
      "CDK"
    ],
    "overview": "A modern, serverless web application that showcases a developer's professional profile with AI-powered personalization features using Next.js and AWS services.",
    "challenge": "Creating personalized portfolio experiences for recruiters while maintaining cost-effective serverless architecture and seamless user experience.",
    "solution": "Next.js frontend with AWS services backend, featuring AI-powered personalization, invisible authentication, and multi-region deployment strategy.",
    "architecture": [
      {
        "name": "Frontend Architecture",
        "details": "Next.js with React 19, TypeScript, Apollo Client for GraphQL, TailwindCSS for styling, and centralized auth context"
      },
      {
        "name": "Backend Architecture",
        "details": "AWS AppSync GraphQL API, Lambda resolvers, DynamoDB storage, Amazon Bedrock AI integration, S3 & CloudFront hosting"
      },
      {
        "name": "Infrastructure as Code",
        "details": "AWS CDK multi-stack approach with environment-based deployments and automated CI/CD pipeline"
      }
    ],
    "technicalShowcases": [
      {
        "title": "Lambda@Edge Authentication",
        "description": "The authentication system requires no user login actions by intercepting HTTP requests at CloudFront edge locations using Lambda@Edge functions. When a recruiter accesses a personalized link containing a visitor token, the edge function validates the token against DynamoDB and performs an AdminInitiateAuth call to AWS Cognito to generate JWT tokens for a virtual user. The function sets HttpOnly cookies (AccessToken, IdToken, LinkId) in response headers, enabling the static Next.js frontend to make authenticated GraphQL requests without user interaction. The implementation uses viewer-request events to intercept incoming requests and viewer-response events to inject authentication cookies, with graceful handling for standard website visitors and personalized features available for recruiters using special links.",
        "highlights": [
          "Lambda@Edge functions execute at 200+ CloudFront edge locations for sub-100ms authentication latency",
          "Virtual Cognito users created via AdminInitiateAuth API calls eliminate traditional login requirements",
          "HttpOnly cookies (AccessToken, IdToken, LinkId) set by edge functions maintain session state across static frontend",
          "Viewer-request/viewer-response event handling enables token validation and cookie injection in a single request cycle",
          "Static asset bypassing (_next/, .js, .css) prevents unnecessary Lambda@Edge invocations and reduces costs",
          "Graceful fallback to original request ensures system resilience when authentication components fail"
        ]
      },
      {
        "title": "Bedrock AI Integration",
        "description": "The AI system integrates with Amazon Bedrock using Claude 3.5 Sonnet through a model adapter pattern that abstracts different AI providers. The BedrockRuntimeClient sends InvokeModelCommand requests with JSON payloads formatted according to the model's API specification. Conversation history is maintained in DynamoDB using role-based message storage (user/assistant) with timestamps and message limits to improve user experience by keeping responses focused and concise. The system implements dynamic prompt generation incorporating recruiter context and developer profile data for personalized responses. Fine-tuned rules keep responses factual and grounded, combined with low temperature settings, with token limits ensuring concise answers and graceful degradation when Bedrock is unavailable.",
        "highlights": [
          "Model adapter pattern supports multiple AI providers through standardized formatPrompt/parseResponse interfaces",
          "Claude 3.5 Sonnet integration uses Bedrock's latest API specification for optimal performance",
          "Conversation history stored in DynamoDB with message limits to prevent item size constraints",
          "Dynamic prompt generation incorporates recruiter context and developer profile for personalized responses",
          "Temperature settings optimized for consistent Q&A and creative greetings with token limits for concise responses",
          "Graceful degradation to static content when Bedrock API calls fail or timeout",
          "Role-based message storage (user/assistant) with timestamps enables conversation context tracking"
        ]
      },
      {
        "title": "Cost-Optimized Serverless Design",
        "description": "The system achieves low operational costs through careful serverless component selection and configuration. S3 static hosting eliminates server costs entirely, with CloudFront CDN providing global distribution at competitive pricing. Lambda functions provide fast, cheap, and scalable compute, scaling from zero with millisecond billing precision within free tier limits. DynamoDB uses on-demand billing eliminating capacity planning, while AppSync GraphQL API uses per-request pricing with built-in caching. Lambda@Edge functions are optimized to bypass static assets, minimizing invocation costs. The entire stack typically operates under $5/month for moderate traffic, with linear cost scaling and zero fixed infrastructure costs.",
        "highlights": [
          "S3 static hosting eliminates server costs entirely, with CloudFront CDN providing competitive global distribution pricing",
          "Lambda functions provide serverless compute that scales to zero when unused, staying within monthly free tier limits",
          "DynamoDB on-demand billing charges only for actual read/write operations, eliminating fixed costs",
          "AppSync GraphQL API uses per-request pricing with built-in caching to reduce redundant data fetching costs",
          "Lambda@Edge optimized to bypass static assets, minimizing authentication-related invocation costs",
          "Zero fixed infrastructure costs - entire stack scales to $0 when unused",
          "Linear cost scaling only occurs with significant traffic increases, maintaining predictable economics"
        ]
      },
      {
        "title": "Multi-Environment Deployment",
        "description": "The deployment system uses local automation scripts and cloud-based CI/CD pipelines for different development workflows. Local deployment is handled by a bash script that orchestrates pnpm commands across infrastructure and frontend directories, including CDK provisioning, SSM parameter synchronization, Next.js production builds, S3 publishing, and CloudFront cache invalidation. The CI/CD pipeline uses GitHub Actions to trigger AWS CodePipeline based on branch merges. Infrastructure as Code is implemented using AWS CDK with TypeScript, managing multi-stack deployments for web hosting, AI services, and data storage. The system uses an internal CLI API with shared code structure and manager classes for efficient business logic separation.",
        "highlights": [
          "Bash deployment script (deploy.sh) orchestrates pnpm commands across infrastructure and frontend directories",
          "GitHub Actions triggers AWS CodePipeline based on branch merges (dev→dev pipeline, main→prod pipeline)",
          "AWS CDK with TypeScript manages multi-stack Infrastructure as Code deployments",
          "Environment isolation through separate AWS accounts and SSM parameter namespacing (/portfolio/env/)",
          "Parameter synchronization commands support preview, apply, and cleanup of obsolete SSM parameters",
          "Forward-only deployments support version management through code reversion and pipeline re-execution",
          "Multi-service environment generation (frontend, link-generator) from deployed stack outputs"
        ]
      }
    ],
    "archPatterns": [
      "Serverless Architecture: Pay-per-use model with Lambda, AppSync, and DynamoDB",
      "Event-Driven Design: AI processing triggered by recruiter interactions",
      "Multi-Region Strategy: Frontend in US, backend in EU for data residency"
    ],
    "performance": [
      "Cost optimization: <$5/month operational costs",
      "Global CDN: CloudFront distribution for sub-100ms response times",
      "Serverless scaling: Auto-scaling from 0 to handle traffic spikes"
    ],
    "developerId": "DEVELOPER_PROFILE"
  },
  {
    "id": "proj-2",
    "title": "Image Processor CLI",
    "slug": "image-processor",
    "icon": "Images",
    "description": "A production-ready Python application for batch image processing with enterprise-level reliability, concurrent processing, and containerized deployment.",
    "status": "Completed",
    "highlights": [
      "Concurrent batch processing with ThreadPoolExecutor",
      "EXIF-aware rotation with metadata preservation",
      "Production-ready containerization with Alpine Linux",
      "Comprehensive test suite with parametrized tests"
    ],
    "techStack": [
      "Python",
      "Pillow (PIL)",
      "piexif",
      "Docker",
      "Alpine Linux",
      "pytest",
      "ThreadPoolExecutor",
      "tqdm",
      "uv"
    ],
    "overview": "A production-ready Python application for batch image processing with enterprise-level reliability, concurrent processing, and containerized deployment.",
    "challenge": "Processing large image batches manually is time-consuming, lacks proper EXIF handling, concurrent processing, and containerized deployment options.",
    "solution": "Containerized CLI tool with ThreadPoolExecutor concurrency, EXIF metadata preservation, and complete development/deployment pipeline.",
    "architecture": [
      {
        "name": "Processing Engine",
        "details": "Concurrent image processing using ThreadPoolExecutor with support for JPEG/PNG formats and EXIF metadata handling"
      },
      {
        "name": "CLI Interface",
        "details": "Argument parsing with argparse, input validation, error handling, and flexible task selection system"
      },
      {
        "name": "Container Infrastructure",
        "details": "Multi-stage Docker build using uv package manager with development and production configurations"
      }
    ],
    "technicalShowcases": [],
    "archPatterns": [
      "Command Pattern: Each operation (resize, blur, rotate) implements consistent interface",
      "Factory Pattern: Task selection maps string commands to processing functions",
      "Pipeline Pattern: Validation → Processing → Output with error handling"
    ],
    "performance": [
      "Thread-based parallelism scales with available CPU cores",
      "Memory efficiency: processes images individually to avoid bloat",
      "Container optimization: multi-stage builds reduce deployment time"
    ],
    "developerId": "DEVELOPER_PROFILE"
  },
  {
    "id": "proj-3",
    "title": "Web3 Snapshot",
    "slug": "web3snapshot",
    "icon": "Aperture",
    "description": "A production-ready full-stack application providing real-time cryptocurrency market analysis with microservices architecture and Server-Sent Events.",
    "status": "Completed",
    "highlights": [
      "Real-time market data streaming with Server-Sent Events",
      "Microservices container architecture with service isolation",
      "Advanced caching strategies with Redis pub/sub",
      "Comprehensive testing with pytest and React Testing Library"
    ],
    "techStack": [
      "React",
      "Flask",
      "Redis",
      "Docker",
      "SQLite",
      "Nginx",
      "Gunicorn",
      "Zustand",
      "SCSS",
      "pytest"
    ],
    "overview": "A production-ready full-stack application providing real-time cryptocurrency market analysis with microservices architecture and Server-Sent Events.",
    "challenge": "Cryptocurrency markets move rapidly requiring real-time data access, comprehensive tokenomics analysis, and historical trends in digestible format.",
    "solution": "Containerized dashboard with live CoinGecko API integration, Redis pub/sub messaging, Server-Sent Events, and responsive React interface.",
    "architecture": [
      {
        "name": "Frontend (React SPA)",
        "details": "React 18 with functional components, SCSS styling, real-time updates via Server-Sent Events, interactive tables with sorting/filtering"
      },
      {
        "name": "Backend API (Flask)",
        "details": "RESTful API with Redis caching, real-time streaming endpoints, pub/sub messaging system, environment-specific configurations"
      },
      {
        "name": "Data Processing Engine",
        "details": "Automated CoinGecko API fetching, MC/FDV calculations, intelligent data diffing, cron-based scheduling"
      },
      {
        "name": "Infrastructure",
        "details": "Multi-container Docker architecture, Redis caching/pub-sub, SQLite database, Nginx reverse proxy with SSL/TLS"
      }
    ],
    "technicalShowcases": [],
    "archPatterns": [
      "Microservices Design: Separate containers for frontend, backend, caching, enabling independent scaling",
      "Event-Driven Architecture: Redis pub/sub decouples data processing from API responses",
      "Observer Pattern: Server-Sent Events allow multiple clients to receive real-time updates"
    ],
    "performance": [
      "Redis caching with intelligent cache invalidation",
      "Data diffing algorithms reduce unnecessary database writes",
      "Server-Sent Events eliminate polling overhead"
    ],
    "developerId": "DEVELOPER_PROFILE"
  }
]
